{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "999a3555-cea7-4dcd-bd15-7de648f7afb5",
   "metadata": {},
   "source": [
    "# Simple semantics and \"federated upload\" of datasets via python and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "198b4f41-0516-494b-ad7d-1ca947199dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load InteractiveShell: enable to show all output generated in a cell, not only the last one\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import os\n",
    "os.environ[\"REQUESTS_CA_BUNDLE\"] = \"/etc/ssl/certs/ca-certificates.crt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112522f9-3018-47b5-9c19-0d36e3e2a652",
   "metadata": {},
   "source": [
    "# Slice the dataset and upload via the mesh\n",
    "\n",
    "In this notebook, we slice the original dataset (stored in `../pmdco2_tto_example.ttl`) and distribute the slices to 3 `ontodocker` instances on the mesh. We will slice it into 3 pieces corresponding to the orientation in which the respective specimen was cut from the steel-sheet relative to the rolling direction. We then serialize the generated graphs as turtle-files and do the upload."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895d9a66-c234-4d8c-ae39-2d120beab437",
   "metadata": {},
   "source": [
    "## Create three subgraphs\n",
    "These orientations are *parallel*, *perpendicular* and *diagonal*. Each of the resulting graphs/ datasets should contain all \"general\" information of the original dataset, i.e. information like general metadata, which cannot be assigned to a specific orientation.\n",
    "\n",
    "To do that, we have to\n",
    "- collect all processes with a rolling direction\n",
    "- collect all other triples belonging to the resp. process\n",
    "- collect all triples which are not related to a rolling diretion\n",
    "\n",
    "The resulting graphs then are finally serialized as turtle-files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de93f02f-d63d-452a-9ac5-676c30df984b",
   "metadata": {},
   "source": [
    "First, we import the required objects from `rdflib` and define namespaces which are used:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54c46209-9df2-4894-bbf1-050e12482986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, Namespace, URIRef, Literal\n",
    "from rdflib.namespace import RDF, XSD\n",
    "\n",
    "ns_pmdco = Namespace(\"https://w3id.org/pmd/co/\")\n",
    "ns_tte = Namespace(\"https://w3id.org/pmd/ao/tte/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5b1ad7-52ae-4e3b-9294-f3381d2446a1",
   "metadata": {},
   "source": [
    "Instantiate the `Graph()`-object for the original (full) graph/dataset and parse the data into it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6afd9529-7d12-43fd-9a51-8c61e0f1802c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N1c449a44e8424e8c8b6ec9961be23c53 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Graph()\n",
    "g.parse(\"../datasets/pmdco2_tto_example.ttl\", format=\"turtle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7146d96c-ace6-4d23-9de8-9e6478c9edf5",
   "metadata": {},
   "source": [
    "Now, we collect all **processes** accossiated with a rolling direction. Using `set()` prevents the occurance of doubled information (dublicates). We do this by iterating over all triples from the full graph `g` and searching all triples with predicate \"pmdco.value\" and the string \"*_rollingDirection\" in their subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efdc4eb6-97bd-4415-a1ab-167377df11eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "processes_parallel = set()\n",
    "processes_perpendicular = set()\n",
    "processes_diagonal = set()\n",
    "\n",
    "for rolling_dir in g.subjects(predicate=ns_pmdco.value, object=None):\n",
    "    if \"_rollingDirection\" in str(rolling_dir):\n",
    "        for s, p, o in g.triples((rolling_dir, ns_pmdco.value, None)):\n",
    "            value = str(o).strip().lower()\n",
    "            for proc in g.subjects(predicate=ns_pmdco.characteristic, object=rolling_dir):\n",
    "                if value == \"in rolling direction\":\n",
    "                    processes_parallel.add(proc)\n",
    "                elif value == \"perpendicular to rolling direction\":\n",
    "                    processes_perpendicular.add(proc)\n",
    "                elif value == \"diagonal to rolling direction\":\n",
    "                    processes_diagonal.add(proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7d97b3-aa26-4d79-bb11-b91550b47c98",
   "metadata": {},
   "source": [
    "Next, we collect al other triples, which are acossiated with the processes from above. For this, we define a function iterating over all triples as long as the triples IRI is from the TTE namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57d85623-f136-4b33-9aaf-bd2a539d19e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_tripels(process, graph, collected=None):\n",
    "    if collected is None:\n",
    "        collected = set()\n",
    "    for t in graph.triples((process, None, None)):\n",
    "        if t not in collected:\n",
    "            collected.add(t)\n",
    "            # collect recursively, if object (t[2]) is \"URIRef\" (IRI) in the same namespace (TTE)\n",
    "            if isinstance(t[2], URIRef) and str(t[2]).startswith(str(ns_tte)):\n",
    "                collect_tripels(t[2], graph, collected)\n",
    "    return collected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa637c1-e17f-4171-bc1a-93d82fcb09ce",
   "metadata": {},
   "source": [
    "Now we actualy collect the triples by iterating over all triples and creating the unions of triples belonging to a process (which, in turn, is accossiated with an orientation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c340a29e-ee76-4450-897c-97afaebc8e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tripels_parallel = set()\n",
    "tripels_perpendicular = set()\n",
    "tripels_diagonal = set()\n",
    "\n",
    "for proc in processes_parallel:\n",
    "    tripels_parallel |= collect_tripels(proc, g) # (a|=b) == (a = a|b) == (a.update(b)) == (a = a.union(b)); in-place Union/Vereinigung\n",
    "for proc in processes_perpendicular:\n",
    "    tripels_perpendicular |= collect_tripels(proc, g)\n",
    "for proc in processes_diagonal:\n",
    "    tripels_diagonal |= collect_tripels(proc, g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d9dbc4-1d2d-4dc7-9786-8482e3226a1d",
   "metadata": {},
   "source": [
    "Also, we need to collect general information which is not related to a process at all. We do this, by first creating the graph which *only* contains information related to a process and substracting this from the overall full graph `g`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d959126-8b6b-4212-a58a-d5cb533eaa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_tripels = tripels_parallel | tripels_perpendicular | tripels_diagonal # (c = a | b) == (c = a.union(b)); Union/Vereinigung\n",
    "general_tripels = set(g) - rolling_tripels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57c9459-ce52-4ad1-a1f3-efb4a2def3cf",
   "metadata": {},
   "source": [
    "Finally, we create the graphs from the union of the resp. (set of process-realted) triples and the general triples. The line magic `%%capture` suppresses cell output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32fe4b04-22bd-49aa-8968-dc45b33554b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap\n",
    "\n",
    "g_parallel = Graph()\n",
    "g_perpendicular = Graph()\n",
    "g_diagonal = Graph()\n",
    "for t in tripels_parallel | general_tripels:\n",
    "    g_parallel.add(t)\n",
    "for t in tripels_perpendicular | general_tripels:\n",
    "    g_perpendicular.add(t)\n",
    "for t in tripels_diagonal | general_tripels:\n",
    "    g_diagonal.add(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0ca53d-84ae-435d-affb-fe20158d580a",
   "metadata": {},
   "source": [
    "The final step now is to adjust the resource loactions where to find the CSV files referenced in the datasets. Formerly, they were located at some github repsitory. First, we define a function which performs URL replacements in the graph objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6750b581-d668-4a96-83df-5f53ecff121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_url_replacements(g: Graph, replacements: dict[str, str]):\n",
    "    \"\"\"\n",
    "    In-place replacement of csvw:url objects according to a mapping.\n",
    "    \n",
    "    Args:\n",
    "        g: rdflib.Graph loaded with your triples.\n",
    "        replacements: dict mapping old URL strings -> new URL strings.\n",
    "    \n",
    "    Returns:\n",
    "        List of (table_subject_uri, old_url_str, new_url_str) for each change.\n",
    "    \"\"\"\n",
    "    ns_csvw = Namespace(\"http://www.w3.org/ns/csvw#\")\n",
    "    changes = []\n",
    "\n",
    "    for table, old in g.subject_objects(predicate=ns_csvw.url):\n",
    "        old_s = str(old)\n",
    "        new_val = replacements.get(old_s)\n",
    "        if new_val is None:\n",
    "            continue\n",
    "\n",
    "        # Preserve node kind: URIRef stays IRI; Literal stays xsd:anyURI\n",
    "        new_node = URIRef(new_val) if isinstance(old, URIRef) else Literal(new_val, datatype=XSD.anyURI)\n",
    "\n",
    "        if new_node != old:\n",
    "            g.remove((table, ns_csvw.url, old))\n",
    "            g.add((table, ns_csvw.url, new_node))\n",
    "            changes.append((table, old_s, new_val))\n",
    "\n",
    "    return changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90f417a-676e-4b36-8d96-1f446a25823c",
   "metadata": {},
   "source": [
    "Then, we define the repalcements to be performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ea9b01d-ce71-4425-a085-a566a9dcfae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements_parallel = {\n",
    "    \"https://github.com/materialdigital/application-ontologies/tree/main/tensile_test_ontology_TTO/data/primary_data/Zx1.csv\": \"https://data.mpi-susmat.pmd.internal/Zx1.csv\",\n",
    "    \"https://github.com/materialdigital/application-ontologies/tree/main/tensile_test_ontology_TTO/data/primary_data/Zx2.csv\": \"https://data.mpi-susmat.pmd.internal/Zx2.csv\",\n",
    "    \"https://github.com/materialdigital/application-ontologies/tree/main/tensile_test_ontology_TTO/data/primary_data/Zx3.csv\": \"https://data.mpi-susmat.pmd.internal/Zx3.csv\",\n",
    "    \"https://github.com/materialdigital/application-ontologies/tree/main/tensile_test_ontology_TTO/data/primary_data/Zx4.csv\": \"https://data.mpi-susmat.pmd.internal/Zx4.csv\",\n",
    "}\n",
    "replacements_perpendicular = {\n",
    "    \"https://github.com/materialdigital/application-ontologies/tree/main/tensile_test_ontology_TTO/data/primary_data/Zy1.csv\": \"https://data.kit-3.pmd.internal/S355/01_primary_data/Zy1.csv\",\n",
    "    \"https://github.com/materialdigital/application-ontologies/tree/main/tensile_test_ontology_TTO/data/primary_data/Zy2.csv\": \"https://data.kit-3.pmd.internal/S355/01_primary_data/Zy2.csv\",\n",
    "    \"https://github.com/materialdigital/application-ontologies/tree/main/tensile_test_ontology_TTO/data/primary_data/Zy3.csv\": \"https://data.kit-3.pmd.internal/S355/01_primary_data/Zy3.csv\",\n",
    "    \"https://github.com/materialdigital/application-ontologies/tree/main/tensile_test_ontology_TTO/data/primary_data/Zy4.csv\": \"https://data.kit-3.pmd.internal/S355/01_primary_data/Zy4.csv\",\n",
    "}\n",
    "replacements_diagonal = {\n",
    "    \"https://github.com/materialdigital/application-ontologies/tree/main/tensile_test_ontology_TTO/data/primary_data/Zd2.csv\": \"https://ckan.iwm.pmd.internal/en/dataset/1bae2004-1729-46c1-8aeb-25e2652b8485/resource/c6d930b7-e06b-42f0-8a6e-c2ec5f721b21/download/zd2.csv\",\n",
    "    \"https://github.com/materialdigital/application-ontologies/tree/main/tensile_test_ontology_TTO/data/primary_data/Zd3.csv\": \"https://ckan.iwm.pmd.internal/en/dataset/1bae2004-1729-46c1-8aeb-25e2652b8485/resource/4ee98330-c256-4c0c-abed-08ff8df6af0f/download/zd3.csv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c010567f-7f06-4b5d-8e40-c341603595a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(rdflib.term.URIRef('https://w3id.org/pmd/ao/tte/Zx3_csv'),\n",
       "  'https://github.com/materialdigital/application-ontologies/tree/main/tensile_test_ontology_TTO/data/primary_data/Zx3.csv',\n",
       "  'https://data.mpi-susmat.pmd.internal/Zx3.csv'),\n",
       " (rdflib.term.URIRef('https://w3id.org/pmd/ao/tte/Zx2_csv'),\n",
       "  'https://github.com/materialdigital/application-ontologies/tree/main/tensile_test_ontology_TTO/data/primary_data/Zx2.csv',\n",
       "  'https://data.mpi-susmat.pmd.internal/Zx2.csv'),\n",
       " (rdflib.term.URIRef('https://w3id.org/pmd/ao/tte/Zx4_csv'),\n",
       "  'https://github.com/materialdigital/application-ontologies/tree/main/tensile_test_ontology_TTO/data/primary_data/Zx4.csv',\n",
       "  'https://data.mpi-susmat.pmd.internal/Zx4.csv'),\n",
       " (rdflib.term.URIRef('https://w3id.org/pmd/ao/tte/Zx1_csv'),\n",
       "  'https://github.com/materialdigital/application-ontologies/tree/main/tensile_test_ontology_TTO/data/primary_data/Zx1.csv',\n",
       "  'https://data.mpi-susmat.pmd.internal/Zx1.csv')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(rdflib.term.URIRef('https://w3id.org/pmd/ao/tte/Zy4_csv'),\n",
       "  'https://github.com/materialdigital/application-ontologies/tree/main/tensile_test_ontology_TTO/data/primary_data/Zy4.csv',\n",
       "  'https://data.kit-3.pmd.internal/S355/01_primary_data/Zy4.csv'),\n",
       " (rdflib.term.URIRef('https://w3id.org/pmd/ao/tte/Zy1_csv'),\n",
       "  'https://github.com/materialdigital/application-ontologies/tree/main/tensile_test_ontology_TTO/data/primary_data/Zy1.csv',\n",
       "  'https://data.kit-3.pmd.internal/S355/01_primary_data/Zy1.csv'),\n",
       " (rdflib.term.URIRef('https://w3id.org/pmd/ao/tte/Zy2_csv'),\n",
       "  'https://github.com/materialdigital/application-ontologies/tree/main/tensile_test_ontology_TTO/data/primary_data/Zy2.csv',\n",
       "  'https://data.kit-3.pmd.internal/S355/01_primary_data/Zy2.csv'),\n",
       " (rdflib.term.URIRef('https://w3id.org/pmd/ao/tte/Zy3_csv'),\n",
       "  'https://github.com/materialdigital/application-ontologies/tree/main/tensile_test_ontology_TTO/data/primary_data/Zy3.csv',\n",
       "  'https://data.kit-3.pmd.internal/S355/01_primary_data/Zy3.csv')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(rdflib.term.URIRef('https://w3id.org/pmd/ao/tte/Zd3_csv'),\n",
       "  'https://github.com/materialdigital/application-ontologies/tree/main/tensile_test_ontology_TTO/data/primary_data/Zd3.csv',\n",
       "  'https://ckan.iwm.pmd.internal/en/dataset/1bae2004-1729-46c1-8aeb-25e2652b8485/resource/4ee98330-c256-4c0c-abed-08ff8df6af0f/download/zd3.csv'),\n",
       " (rdflib.term.URIRef('https://w3id.org/pmd/ao/tte/Zd2_csv'),\n",
       "  'https://github.com/materialdigital/application-ontologies/tree/main/tensile_test_ontology_TTO/data/primary_data/Zd2.csv',\n",
       "  'https://ckan.iwm.pmd.internal/en/dataset/1bae2004-1729-46c1-8aeb-25e2652b8485/resource/c6d930b7-e06b-42f0-8a6e-c2ec5f721b21/download/zd2.csv')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%capture cap\n",
    "\n",
    "apply_url_replacements(g_parallel, replacements_parallel)\n",
    "apply_url_replacements(g_perpendicular, replacements_perpendicular)\n",
    "apply_url_replacements(g_diagonal, replacements_diagonal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0180e3-a3b4-4c48-a9fc-cf3d96b51353",
   "metadata": {},
   "source": [
    "Define handles for the datasets and the related files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acf96e2b-a900-4cd4-bbb0-d2d8560872b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetname_parallel = \"pmdco2_tto_example_parallel\"\n",
    "filename_parallel = \"../datasets/\" + datasetname_parallel + \".ttl\"\n",
    "\n",
    "datasetname_perpendicular = \"pmdco2_tto_example_perpendicular\"\n",
    "filename_perpendicular = \"../datasets/\" + datasetname_perpendicular + \".ttl\"\n",
    "\n",
    "datasetname_diagonal = \"pmdco2_tto_example_diagonal\"\n",
    "filename_diagonal = \"../datasets/\" + datasetname_diagonal + \".ttl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e6140b-069c-4484-88c9-1f04a2a82034",
   "metadata": {},
   "source": [
    "Serialize the graphs to turtle-files (`.ttl`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68f3d007-0c3c-44a2-bb5c-2ad1abf615ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N1b020514912d4654a76f063df89e8629 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N52dd40be9fc146ada5a84d5540351a50 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N974f263332124bb4a548b3a2b16015ca (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_parallel.serialize(filename_parallel, format=\"turtle\")\n",
    "g_perpendicular.serialize(filename_perpendicular, format=\"turtle\")\n",
    "g_diagonal.serialize(filename_diagonal, format=\"turtle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073b538f-36b0-4814-87fe-864bace44c19",
   "metadata": {},
   "source": [
    "## Upload the three slices via the mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd02c6d-65b4-4200-914c-66a9bd9ea16c",
   "metadata": {},
   "source": [
    "This part requires some basic knowledge of the mesh-related tools used inthe Demonstrator. Have a look at `01-setup_and_fist_steps.ipynb` for information.  \n",
    "Before any usage of the mesh, we have to point `requests` to the right certificate bundle:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55b5e2f-0be5-4fd2-a0e2-04e7636322b5",
   "metadata": {},
   "source": [
    "populate the mesh-paticipant registry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17aa9ef2-691f-48ca-8ee5-8ec1397170d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/pmd-demonstrator/pmd_mesh-demonstrator/pmd_demo_tools/pmd_demo_tools/mesh_tools.py:606: UserWarning: Failed fetching services for glassomer.pmd.internal: 500 Server Error: Internal Server Error for url: http://mesh-listing.c.pmd.internal/api/v1/pmds/glassomer.pmd.internal.\n",
      "  warnings.warn(f\"Failed fetching services for {zone}: {e}.\", category=UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"REQUESTS_CA_BUNDLE\"] = \"/etc/ssl/certs/ca-certificates.crt\"\n",
    "\n",
    "from pmd_demo_tools import mesh_tools\n",
    "\n",
    "# index all servers\n",
    "partners_full = mesh_tools.mesh_namespace_grouped_by_company()\n",
    "\n",
    "# attach hosted services\n",
    "_ = mesh_tools.attach_services_in_place(partners_full)\n",
    "\n",
    "# fill in web tokens\n",
    "import json\n",
    "with open('../secrets/tokens.json') as f:\n",
    "    tokens = json.load(f, object_hook=mesh_tools.namespace_object_hook())\n",
    "\n",
    "partners_full.Leibniz_Institut_fuer_Werkstofforientierte_Technologien_IWT.iwt.services.ontodocker.token = tokens.Leibniz_Institut_fuer_Werkstofforientierte_Technologien_IWT.ontodocker.token\n",
    "partners_full.Fraunhofer_IWM.iwm.services.ontodocker.token = tokens.Fraunhofer_IWM.ontodocker.token\n",
    "partners_full.KIT.kit_3.services.ontodocker_proxy.token = tokens.KIT.ontodocker_proxy.token\n",
    "partners_full.MPISusMat.mpi_susmat.services.ontodocker.token = tokens.MPISusMat.ontodocker.token\n",
    "\n",
    "# reduce to some selected partners\n",
    "selection = [\"Leibniz_Institut_fuer_Werkstofforientierte_Technologien_IWT\", \"Fraunhofer_IWM\", \"KIT\", \"MPISusMat\"]\n",
    "partners = mesh_tools.select_toplevel(partners_full, selection, deepcopy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a86ba14-e093-43f6-ba6b-7586206822e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leibniz_Institut_fuer_Werkstofforientierte_Technologien_IWT\n",
      "Available SPARQL-endpoints at \"ontodocker.iwt.pmd.internal\":\n",
      "https://ontodocker.iwt.pmd.internal/api/v1/jena/pmdco2_tto_example_parallel/sparql\n",
      "https://ontodocker.iwt.pmd.internal/api/v1/jena/test_dataset/sparql\n",
      "\n",
      "Fraunhofer_IWM\n",
      "Available SPARQL-endpoints at \"ontodocker.iwm.pmd.internal\":\n",
      "https://ontodocker.iwm.pmd.internal/api/v1/jena/test/sparql\n",
      "https://ontodocker.iwm.pmd.internal/api/v1/jena/pmdco2_tto_example_diagonal/sparql\n",
      "\n",
      "KIT\n",
      "Available SPARQL-endpoints at \"ontodocker-proxy.kit-3.pmd.internal\":\n",
      "http://ontodocker-proxy.kit-3.pmd.internal/api/v1/jena/test_dataset/sparql\n",
      "http://ontodocker-proxy.kit-3.pmd.internal/api/v1/jena/pmdco2_tto_example_perpendicular/sparql\n",
      "http://ontodocker-proxy.kit-3.pmd.internal/api/v1/jena/tt_test/sparql\n",
      "\n",
      "MPISusMat\n",
      "Available SPARQL-endpoints at \"ontodocker.mpi-susmat.pmd.internal\":\n",
      "http://ontodocker.mpi-susmat.pmd.internal/api/v1/jena/newset/sparql\n",
      "http://ontodocker.mpi-susmat.pmd.internal/api/v1/jena/test_dataset/sparql\n",
      "http://ontodocker.mpi-susmat.pmd.internal/api/v1/jena/not4all/sparql\n",
      "http://ontodocker.mpi-susmat.pmd.internal/api/v1/jena/test/sparql\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pmd_demo_tools import sparql_tools\n",
    "import requests\n",
    "\n",
    "endpoints = sparql_tools.list_sparql_endpoints(partners, verify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f70927-2b4d-4dc7-95ad-7b154b903831",
   "metadata": {},
   "source": [
    "Optionally delete concurring datasets before uploading: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72c818c5-dc0c-40ce-af02-39ab79b69fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leibniz_Institut_fuer_Werkstofforientierte_Technologien_IWT\n",
      "\n",
      "Deleting dataset pmdco2_tto_example_parallel at \"ontodocker.iwt.pmd.internal\":\n",
      "\"Dataset name pmdco2_tto_example_parallel destroyed\"\n",
      "\n",
      "Deleting dataset pmdco2_tto_example_perpendicular at \"ontodocker.iwt.pmd.internal\":\n",
      "\"No such dataset registered: /pmdco2_tto_example_perpendicular\\n\"\n",
      "\n",
      "Deleting dataset pmdco2_tto_example_diagonal at \"ontodocker.iwt.pmd.internal\":\n",
      "\"No such dataset registered: /pmdco2_tto_example_diagonal\\n\"\n",
      "\n",
      "Fraunhofer_IWM\n",
      "\n",
      "Deleting dataset pmdco2_tto_example_parallel at \"ontodocker.iwm.pmd.internal\":\n",
      "\"401 - Unauthorized\"\n",
      "\n",
      "Deleting dataset pmdco2_tto_example_perpendicular at \"ontodocker.iwm.pmd.internal\":\n",
      "\"401 - Unauthorized\"\n",
      "\n",
      "Deleting dataset pmdco2_tto_example_diagonal at \"ontodocker.iwm.pmd.internal\":\n",
      "\"401 - Unauthorized\"\n",
      "\n",
      "KIT\n",
      "\n",
      "Deleting dataset pmdco2_tto_example_parallel at \"ontodocker-proxy.kit-3.pmd.internal\":\n",
      "\"No such dataset registered: /pmdco2_tto_example_parallel\\n\"\n",
      "\n",
      "Deleting dataset pmdco2_tto_example_perpendicular at \"ontodocker-proxy.kit-3.pmd.internal\":\n",
      "\"Dataset name pmdco2_tto_example_perpendicular destroyed\"\n",
      "\n",
      "Deleting dataset pmdco2_tto_example_diagonal at \"ontodocker-proxy.kit-3.pmd.internal\":\n",
      "\"No such dataset registered: /pmdco2_tto_example_diagonal\\n\"\n",
      "\n",
      "MPISusMat\n",
      "\n",
      "Deleting dataset pmdco2_tto_example_parallel at \"ontodocker.mpi-susmat.pmd.internal\":\n",
      "\"No such dataset registered: /pmdco2_tto_example_parallel\\n\"\n",
      "\n",
      "Deleting dataset pmdco2_tto_example_perpendicular at \"ontodocker.mpi-susmat.pmd.internal\":\n",
      "\"No such dataset registered: /pmdco2_tto_example_perpendicular\\n\"\n",
      "\n",
      "Deleting dataset pmdco2_tto_example_diagonal at \"ontodocker.mpi-susmat.pmd.internal\":\n",
      "\"No such dataset registered: /pmdco2_tto_example_diagonal\\n\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasetname_list = [datasetname_parallel, datasetname_perpendicular, datasetname_diagonal]\n",
    "filename_list = [filename_parallel, filename_perpendicular, filename_diagonal]\n",
    "\n",
    "for company, server, service_key, service in mesh_tools.iter_servers_with_services_matching(partners, [\"*ontodocker*\"]):\n",
    "    print(company+ \"\\n\")\n",
    "    address = service.address\n",
    "    token = service.token\n",
    "    for datasetname in datasetname_list:\n",
    "        try:\n",
    "            headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "            timeout=(3, 3)\n",
    "            result = requests.delete(f'https://{address}/api/v1/jena/{datasetname}', headers=headers, timeout=timeout, verify=True).content.decode()\n",
    "            print(f'Deleting dataset {datasetname} at \"{address}\":')\n",
    "            print(result)\n",
    "            print(\"\")\n",
    "        except Exception as e:\n",
    "            print (f\"An error occurred for the service with address '{address}':\\n\")\n",
    "            print(str(type(e))+\"\\n\"+str(e)+\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24f20b1-8b85-41c5-b934-5092b9a25a08",
   "metadata": {},
   "source": [
    "Do the upload via http requests to the ontodocker api:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "098d8e55-f780-4504-900a-1b99fe4a7c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating & filling dataset at \"ontodocker.iwt.pmd.internal\":\n",
      "--> \"Dataset name pmdco2_tto_example_parallel created\"\n",
      "Upload \"../datasets/pmdco2_tto_example_parallel.ttl\" to dataset \"pmdco2_tto_example_parallel\" at \"ontodocker.iwt.pmd.internal\"\n",
      "--> \"Upload succeeded { \\n  \\\"count\\\" : 1378 ,\\n  \\\"tripleCount\\\" : 1378 ,\\n  \\\"quadCount\\\" : 0\\n}\\n\"\n",
      "\n",
      "Creating & filling dataset at \"ontodocker-proxy.kit-3.pmd.internal\":\n",
      "--> \"Dataset name pmdco2_tto_example_perpendicular created\"\n",
      "Upload \"../datasets/pmdco2_tto_example_perpendicular.ttl\" to dataset \"pmdco2_tto_example_perpendicular\" at \"ontodocker-proxy.kit-3.pmd.internal\"\n",
      "--> \"Upload succeeded { \\n  \\\"count\\\" : 1378 ,\\n  \\\"tripleCount\\\" : 1378 ,\\n  \\\"quadCount\\\" : 0\\n}\\n\"\n",
      "\n",
      "Creating & filling dataset at \"ontodocker.iwm.pmd.internal\":\n",
      "--> \"401 - Unauthorized\"\n",
      "Upload \"../datasets/pmdco2_tto_example_diagonal.ttl\" to dataset \"pmdco2_tto_example_diagonal\" at \"ontodocker.iwm.pmd.internal\"\n",
      "--> \"401 - Unauthorized\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#select institutes to upload data to\n",
    "ontodockers = [partners.Leibniz_Institut_fuer_Werkstofforientierte_Technologien_IWT.iwt.services.ontodocker,\n",
    "               partners.KIT.kit_3.services.ontodocker_proxy,\n",
    "               partners.Fraunhofer_IWM.iwm.services.ontodocker\n",
    "              ]\n",
    "\n",
    "for (ontodocker, datasetname, filename) in zip(ontodockers, datasetname_list, filename_list):\n",
    "    address = ontodocker.address\n",
    "    token = ontodocker.token\n",
    "    \n",
    "    endpoint = f'https://{address}/api/v1/jena/{datasetname}'\n",
    "    headers = {\"Authorization\": f'Bearer {token}'}\n",
    "\n",
    "    # create dataset\n",
    "    print(f'Creating & filling dataset at \"{address}\":')\n",
    "    print(\"--> \"+ requests.put(endpoint, headers=headers, verify=True).content.decode())\n",
    "\n",
    "    # uplaod file\n",
    "    print(f'Upload \"{filename}\" to dataset \"{datasetname}\" at \"{address}\"')\n",
    "    print(\"--> \" + requests.post(endpoint, headers=headers, files={'file': open(filename, 'rb')}, verify=True).content.decode())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beffad63-0c29-460e-8e56-966136f1d3fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
