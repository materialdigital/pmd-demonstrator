{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a939b67-1a73-47be-8662-b5b846c4c641",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7cbab0e-1997-47e8-8b6d-64e6cccf37fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "# reload modules automatically before each cell\n",
    "%autoreload 2\n",
    "\n",
    "%config IPCompleter.evaluation='unsafe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c1cb2e4-883f-49ac-8d92-949c1303c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow import Workflow as workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33b2eacd-ae2a-4d89-ab9b-4b74b5c1c34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "os.environ[\"REQUESTS_CA_BUNDLE\"] = \"/etc/ssl/certs/ca-certificates.crt\" # if not already set by the OS; doesn't hurt\n",
    "\n",
    "# fixes a bug in SPARQLwrapper\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# importing pandas to make printed dataframes prettier\n",
    "import pandas as pd, hashlib\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.colheader_justify', 'left')\n",
    "pd.set_option('display.width', 200)\n",
    "\n",
    "from pmd_demo_tools import mesh_tools, sparql_tools\n",
    "from pmd_demo_tools.query_collection import S355queries\n",
    "S355queries = S355queries()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1f98d5-9db7-43d9-b7f9-2498595b745d",
   "metadata": {},
   "source": [
    "# Node definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d689aca-3fcc-4114-b193-e46fab903d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "@workflow.wrap.as_function_node(\"partners\")\n",
    "def populate_mesh_registry(token_file_path: str | None) -> mesh_tools.RecursiveNamespace:\n",
    "    # read in all servers on the mesh\n",
    "    partners = mesh_tools.mesh_namespace_grouped_by_company()\n",
    "\n",
    "    # attach hosted services\n",
    "    _ = mesh_tools.attach_services_in_place(partners)\n",
    "    \n",
    "    if token_file_path is not None:\n",
    "        with open(token_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            tokens = json.load(f, object_hook=mesh_tools.namespace_object_hook())\n",
    "\n",
    "        mesh_tools.attach_tokens_to_partners(partners, tokens, overwrite=True, warn_missing=False)\n",
    "\n",
    "    return partners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9489d438-3a7b-4408-8dde-37621cf67bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@workflow.wrap.as_function_node(\"partners\")\n",
    "def reduce_mesh_registry(partners_in: mesh_tools.RecursiveNamespace,\n",
    "                        selection: list[str]) -> mesh_tools.RecursiveNamespace:\n",
    "    partners = mesh_tools.select_toplevel(partners_in, selection, deepcopy=True)\n",
    "    return partners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3397a808-4a65-4734-8b93-9980407cb05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@workflow.wrap.as_dataclass_node\n",
    "class MeshQueryResponse:\n",
    "    results_rns: mesh_tools.RecursiveNamespace\n",
    "    query = sparql_tools.SparqlQuery\n",
    "\n",
    "@workflow.wrap.as_function_node(\"MeshQueryResponse\")\n",
    "def query_datasets_on_mesh(partners: mesh_tools.RecursiveNamespace,\n",
    "                           query: sparql_tools.SparqlQuery,\n",
    "                           datasets: list[str] | None = None,\n",
    "                           print_to_screen: bool = False) -> MeshQueryResponse:\n",
    "    results = sparql_tools.federated_query(partners=partners, datasets=datasets, query=query.query, columns=query.headers, print_to_screen=print_to_screen)\n",
    "    results_rns = mesh_tools.RecursiveNamespace(**results)\n",
    "    return MeshQueryResponse(results_rns=results_rns,\n",
    "                             query=query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c412ec7f-85e1-4036-83d4-2805dfb99964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "@workflow.wrap.as_dataclass_node\n",
    "class ElasticModulusCalculation:\n",
    "    elastic_modulus: float\n",
    "    variance_elastic_modulus: float\n",
    "    stress_offset: float\n",
    "    variance_stress_offset: float\n",
    "    elastic_strain_limit: float\n",
    "    elastic_limit_index: int\n",
    "\n",
    "def lin_func(x,a,b):\n",
    "        return a*x+b\n",
    "\n",
    "@workflow.wrap.as_function_node\n",
    "def calc_elastic_modulus(stress: np.array, \n",
    "                         strain: np.array, \n",
    "                         elastic_strain_limit: float = 0.001,\n",
    "                        ) -> ElasticModulusCalculation:\n",
    " \n",
    "    elastic_limit_index = 0\n",
    "    while strain[elastic_limit_index] <= elastic_strain_limit:\n",
    "        elastic_limit_index += 1\n",
    "\n",
    "    popt, pcov = curve_fit(lin_func, strain[:elastic_limit_index+1], stress[:elastic_limit_index+1], p0=np.asarray([400000.,-1000000.]))\n",
    "\n",
    "    elastic_modulus = popt[0]\n",
    "    stress_offset = popt[1]\n",
    "    variance_elastic_modulus = pcov[0,0]\n",
    "    variance_stress_offset = pcov[1,1]\n",
    "    elastic_strain_limit = strain[elastic_limit_index]\n",
    "    return ElasticModulusCalculation(elastic_modulus=elastic_modulus,\n",
    "                                     variance_elastic_modulus=variance_elastic_modulus,\n",
    "                                     stress_offset=stress_offset,\n",
    "                                     variance_stress_offset=variance_stress_offset,\n",
    "                                     elastic_strain_limit=elastic_strain_limit,\n",
    "                                     elastic_limit_index=elastic_limit_index,\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28255535-3b41-4843-bbf2-eb6257fa8d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@workflow.wrap.as_dataclass_node\n",
    "class OffsetYieldCalculation:\n",
    "    offset_strain: float\n",
    "    yield_stress: float\n",
    "    yield_strain: float\n",
    "\n",
    "@workflow.wrap.as_function_node(\"OffsetYieldCalculation\")\n",
    "def offset_yield_calculation(stress: np.array, strain: np.array, elastic_modulus: float | None = None, offset_strain: float = 0.002) -> OffsetYieldCalculation:\n",
    "    if elastic_modulus is None:\n",
    "        E = calc_elastic_modulus(stress=stress, strain=strain)\n",
    "        elastic_modulus = E.elastic_modulus\n",
    "        \n",
    "    offset_elastic_line = elastic_modulus * (strain - offset_strain)\n",
    "    # difference between curves\n",
    "    delta = stress - offset_elastic_line\n",
    "\n",
    "    # find indices where sign changes (curve intersection)\n",
    "    sign = np.sign(delta)\n",
    "    # treat exact zeros as positive to avoid double crossings\n",
    "    sign[sign == 0] = 1.0\n",
    "    crossings = np.where(np.diff(sign) != 0)[0]\n",
    "\n",
    "    if len(crossings) == 0:\n",
    "        # fallback: closest point if we never actually cross\n",
    "        arg = np.argmin(np.abs(delta))\n",
    "        yield_strain = strain[arg]\n",
    "        yield_stress = stress[arg]\n",
    "    else:\n",
    "        i = crossings[0]  # first crossing\n",
    "        # linear interpolation in [i, i+1] on delta = 0\n",
    "        x0, x1 = strain[i], strain[i + 1]\n",
    "        d0, d1 = delta[i], delta[i + 1]\n",
    "\n",
    "        # avoid division by zero if two deltaâ€™s are equal (very degenerate)\n",
    "        if d1 == d0:\n",
    "            yield_strain = x0\n",
    "            yield_stress = stress[i]\n",
    "        else:\n",
    "            # strain at intersection (delta == 0)\n",
    "            yield_strain = x0 - d0 * (x1 - x0) / (d1 - d0)\n",
    "\n",
    "            # linearly interpolate stress at that strain\n",
    "            s0, s1 = stress[i], stress[i + 1]\n",
    "            yield_stress = s0 + (s1 - s0) * (yield_strain - x0) / (x1 - x0)\n",
    "\n",
    "    return OffsetYieldCalculation(offset_strain=offset_strain,\n",
    "                                  yield_stress=yield_stress,\n",
    "                                  yield_strain=yield_strain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5717f513-1a8c-4026-b281-b8aedadb05df",
   "metadata": {},
   "source": [
    "# Assign queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fff811-8be3-4d43-ac87-93bbf293072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "orientation_query = S355queries.orientation()\n",
    "csv_url_query = S355queries.csv_url()\n",
    "csv_column_query = S355queries.csv_columns()\n",
    "primary_data_query = S355queries.primary_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2733d2-31b2-45aa-b8aa-ad39b292d574",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca99d1a-f2db-4027-956b-7c1864e8026a",
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_registry = populate_mesh_registry()\n",
    "reduce_registry = reduce_mesh_registry()\n",
    "query_on_mesh = query_datasets_on_mesh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f05bb09-7a50-4338-85fa-fdaf6c5d89a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = workflow(\"S355_tensile_test_analisis\")\n",
    "\n",
    "token_file_path = \"../secrets/tokens.json\"\n",
    "wf.populate_registry = populate_mesh_registry()\n",
    "wf.populate_registry.inputs.token_file_path = token_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded00d8a-988e-4bba-a4f8-61fd223aec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.reduce_registry = reduce_mesh_registry()\n",
    "wf.reduce_registry.inputs.partners_in = wf.populate_registry.outputs.partners\n",
    "\n",
    "selection = [\"Leibniz_Institut_fuer_Werkstofforientierte_Technologien_IWT\", \"Fraunhofer_IWM\", \"KIT\"]\n",
    "wf.reduce_registry.inputs.selection = selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e67a9a9-7050-4caf-9368-0158750cf963",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"pmdco2_tto_example_parallel\", \"pmdco2_tto_example_perpendicular\",\"pmdco2_tto_example_diagonal\"]\n",
    "wf.query_cut_orientation = query_datasets_on_mesh()\n",
    "wf.query_cut_orientation.inputs.partners = wf.reduce_registry.outputs.partners\n",
    "wf.query_cut_orientation.inputs.query = orientation_query\n",
    "wf.query_cut_orientation.inputs.datasets = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e56765-8a32-4803-b835-0d7f1d67640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.run()\n",
    "wf.draw(size=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43df9672-0f62-40fa-8912-ebfd60666b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c354c461-5d77-495e-a095-bd6ace1edf4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
